{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字段\t说明\n",
    "ID\t加密后的ID \n",
    "\n",
    "Age\t0：未知年龄; 1：0-18岁; 2：19-23岁; 3：24-30岁; 4：31-40岁; 5：41-50岁; 6： 51-999岁\n",
    "\n",
    "Gender\t0：未知1：男性2：女性\n",
    "\n",
    "Education\t0：未知学历; 1：博士; 2：硕士; 3：大学生; 4：高中; 5：初中; 6：小学\n",
    "\n",
    "Query List\t搜索词列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"./data/\"\n",
    "train_ori = pd.read_csv(data_source+\"train.csv\", sep=\"###__###\",header = None,encoding=\"utf-8\")\n",
    "train_ori.columns = ['ID', 'Age', 'Gender', 'Education', 'Query_List']\n",
    "test_ori = pd.read_csv(data_source+\"test.csv\", sep=\"###__###\",header = None,encoding=\"utf-8\")\n",
    "test_ori.columns = ['ID', 'Query_List']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  todo list  网址处理\n",
    "#regular1 = re.compile(r'[a-zA-Z]+://[^\\s]*[.com|.cn]*')\n",
    "#将网址和 拆分开来\n",
    "#regular1 = re.compile(r'(http)(s?)(://)')  ###   match http \n",
    "#regular1 = re.compile(r'^((https|http|ftp|rtsp|mms)?:\\/\\/)[^\\s]+')\n",
    "#regular2 = re.compile(r'/([a-z].)[^\\s]*')\n",
    "#train_ori[\"Query\"] = train_ori[\"Query\"].apply(lambda x : re.sub(regular2,\" \",x))\n",
    "train_ori[\"Query\"] = train_ori[\"Query_List\"].apply(lambda x : x.replace(\"\\t\",\" \"))\n",
    "test_ori[\"Query\"]= train_ori[\"Query_List\"].apply(lambda x : x.replace(\"\\t\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=pd.read_csv(\"./stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stopwords=stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.029 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'柔和 双沟 女生 中财网 首页 财经 http pan baidu 1plpjtn9 周公 解梦 大全 查询 2345 曹云金 再讽 郭德纲 总裁 大人 行行好 中财网 第一 财经 传媒 教师节 全文 砸毁 墓碑 黄岩岛 最新 海图 缘来 迟落 甜心 不好惹 梁朝伟 替身 同框 笑傲江湖 电视剧 任贤齐 小起 名字 女孩 名字 海运 行李 堪培拉 诱爱 司少 天价 宝贝 遥控 魔棒 徽信 表情 动态 搞笑 图片 教师节 征文 安微 联通 网上 营业厅 甜宠 百分百 校草 萌萌 未婚妻 豪门 重生 之暖爱 成婚 nikehypershift kd5 好看 韭菜 炒鸡蛋 陈赫 王者 荣耀 虎牙 楚河 三国演义 小说 txt 下载 威县 欧派 好吃 黄岩岛 最新消息 中秋节 诗句 大全 祝福 教师节 征文 菜谱 柔和 双沟 七位数 开奖 以色列 停车场 坍塌 天龙 家庭 农场 7.22 星座 新旧 圣经 合本 下载 wifi 万能钥匙 威灵仙 图片 临泉 长官 天龙 家庭 农场 早安 总统 大人 百合 莲藕 做法 花街 无锡 蚬壳 胃散 触手 忆寒 中秋节 诗句 孟州 电信 电子 发票 鸡丝 做法 临泉 长官 镇桥口 李小刚 农场 朋仇 全民 葱花 蒜苔 炒肉 冰川 图片 kd5 若风 好奇 纸尿裤 清蒸鱼 189.8 平方 重庆 餐馆 发生爆炸 手机 失主 抢劫 https yunpan cn ocsqfgtfya2ewj 家常 做法 三国演义 小说 百度 总裁 掠爱 小舅 太坏 https yunpan cn cmh8tmeyraiww 周公 解梦 坦克 冰川 凉拌 藕片 做法 投票 鸡丝 好吃 时光 掩埋 秘密 小说 下载 中国电信 电子 发票 张续 月亮 诗句 酵母 馒头 方法 赵丽颖 碧瑶 触手 兵长 图集 下载 腾讯 新闻 街头 混战 武警 厦门航空 蚬壳 胃散 茄子 做法 身份 类别 方特 生活 强迫症 表现 白袍 法师 图片 朋仇 广场 小宇 热游 馒头 方法 狡滑 黄石 大冶 东岳 派出所 服务 电话 三国演义 小说 下载 txt http zxjhjc9088.1688 松柏 道馆 10.1 高速 免费 几天 三国演义 小说 txt 柔和 双沟 业务 待遇 酵母 馒头 方法 初中 家教 一对一 辅导 口子 中秋节 祝福 诗句 侠岚 王国 价格表 1001 王国 价格表 批注 殿下 专属 小丫头 无锡 爆炸 茄子 做法 http pan baidu 1cor7gy 大件 行李 邮寄 烟火 陈翔 没想到 真没想到 作文 安徽 滁州 石坝 虎牙 小宇 驾校 培训 长途 骨质 关节炎 膝盖 内侧 怎么回事 虎皮 尖椒 做法 大全 陈翔 女朋友 吻照 世界 23.04 平方根 神将 世界 表情 寻找 成龙 柔和 双沟 三国演义 txt 百度 澳洲 邮寄 行李 费用 触手 1991 星座 校草 成长 暮光 女友 求婚 钢弩 价格 图片 乐乐 课堂 宠妻 成瘾 老婆 魔手 tv 梅河口 济南 火车票 临泉 长官 君子兰 南洋 十大 邪术 电影 炸油条 做法 配方 根号 等于 笑笑 昨日 帝王 吃惊 词语 教师节 征文 朝阳区 庄户 邮编 千百 1991 农历 星座 圣经 合本 免费 下载 水煮 花生米 做法 http pan baidu 1jhbv9pg 十字 徽信 表情 含义 天才 小熊猫 微博长 宠冠六宫 帝王 娇蛮 皇妃 广告 软件 安卓版 萌妻 娇俏帝 总裁 霸爱 小小 新娘 逃婚 花生 好吃 中国 证券网 柔和 双沟 销售 中秋节 诗句 图片 怪病 洗洁精 等于 服装 批发 怀孕 肚子 隐隐作痛 怎么回事 百度 蒜苔 家常 做法 水煮 花生米 天才 小熊猫 作品 袁姗姗 临泉 长官 镇桥口 呼作 白玉 一句 微信 表情 搞笑 图片 滴滴 快车 司机 教师节 手抄报 简单 好看 大冶 公安局 派出所 柔和 双沟 业务 待遇 哺乳期 月经 临泉 长官 水上 乐园 忐忑不安 临泉 长官 李小刚 家庭 农场 电信 电子 发票 报销 岳不群 http pan baidu 1plefcb5 临泉 长官 镇桥口 天龙 农场 凉拌 水煮 花生米 做法 威灵仙 功效 作用 http pan baidu 1o7hnpmy 鸽子 做法 战神 伪高冷 天降 医妃 回家 白颠 初期 症状 天才 小熊猫 首席 萌妻 咬一口 弩弓 商城 三国演义 小说 临泉 长官 镇桥口 植物 养殖 基地 邮储 银行 手机 银行 客户端 下载 花米 好吃 英语 在线翻译 糖醋 鲤鱼 搞笑 微信 表情图片 带字 新婚 似火 鲜妻 胎生 一对 三国演义 教师节 手抄报 http m37189 mustfollow vx mvote net wx 王国 价格表 鱼汤 做法 http www cswanda weixin game1 临泉 长官 镇桥口 私人 农场 临泉 长官 镇桥 口镇 杨营 临泉 长官 天龙 家庭 农场 李子树 根部 脓包 怎么回事 单手 高速 转牌 医学院 路上 徽信 早上好 动态 表情 宝宝 小名 大全 洋气 寂寞 男女 聊天记录 截图 https yunpan cn oc6nhvmrg5j2ur 神将 世界 美丽 秋天 作文 300 http pan baidu 1nu9uizn 钢弩 冰川 世纪 电影 全文 触手 蓝烟 做法 金罐 加多宝 澳洲 托运 行李 15346171303 189 cn 蒜苔 家常 做法 时光 掩埋 秘密 根号 13.6 等于 方特 东方 神画 粉红 花朵 图片 qq 申请 千亿 盛宠 大叔 慢点 http linjiada1989.1688 东方 财富网 首页 http pan baidu 1hraemhe 动力 价格 手机 遥控 魔棒 jzg http pan baidu 1o8cxpmm 行李 托运 澳洲 蚬壳 胃散 副作用 红烧 鲤鱼 触手 tv 中国 财经 信息网 中财网 立方根 800 美食 菜谱 笑傲江湖 电视剧 柔和 双沟 笑傲江湖 品种 名字 图片 滴滴 司机 奇怪 鸡蛋 灌饼 天龙 农家乐 拉拉 歌词 陈翔 女朋友 牢解场 生活 微微一笑 倾城 豪门 少奶奶 谢少 心尖 宠妻'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_stopwords(content):\n",
    "    try:\n",
    "        segs=jieba.lcut(content)\n",
    "        # 去标点、停用词等\n",
    "        segs = list(filter(lambda x:len(x)>1, segs))\n",
    "        segs = list(filter(lambda x:x not in stopwords, segs))\n",
    "        # 将句子处理成  __label__1 词语 词语 词语 ……的形式\n",
    "        #sentences.append(\"__label__\"+str(category)+\" , \"+\" \".join(segs))\n",
    "    except Exception as e:\n",
    "        print(line)\n",
    "    return \" \".join(segs)\n",
    "drop_stopwords(train_ori[\"Query\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ori[\"Query\"] = train_ori[\"Query\"].apply(lambda x : drop_stopwords(x))\n",
    "train_data = train_ori[[\"Education\",\"Query\"]]\n",
    "test_ori[\"Query\"] = test_ori[\"Query\"].apply(lambda x : drop_stopwords(x))\n",
    "test_data = test_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save_file=\"./processed_data/train_data.csv\"\n",
    "train_ori.to_csv(train_save_file)\n",
    "test_save_file=\"./processed_data/test_data.csv\"\n",
    "test_ori.to_csv(test_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>柔和 双沟 女生 中财网 首页 财经 http pan baidu 1plpjtn9 周公 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>广州 厨宝 烤箱 世情 人情 雨送 黄昏 花易落 风干 泪痕 厦门 酒店用品 批发市场 不想...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>钻石 之泪 耳机 盘锦 沈阳 旅顺 公交 辽宁 阜新 车牌 baidu k715 k716 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>受欢迎 狗狗 排行榜 场景 范例 三维 绘图 软件 酸奶 壮观 衣服 网站 动漫 绘图 软件...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>干槽症 自愈 太太 万岁 舒心 美国 干槽症 眼皮 怎么回事 麦当劳 旋风 勺子 吉林市 鹿...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education                                              Query\n",
       "0          4  柔和 双沟 女生 中财网 首页 财经 http pan baidu 1plpjtn9 周公 ...\n",
       "1          3  广州 厨宝 烤箱 世情 人情 雨送 黄昏 花易落 风干 泪痕 厦门 酒店用品 批发市场 不想...\n",
       "2          0  钻石 之泪 耳机 盘锦 沈阳 旅顺 公交 辽宁 阜新 车牌 baidu k715 k716 ...\n",
       "3          3  受欢迎 狗狗 排行榜 场景 范例 三维 绘图 软件 酸奶 壮观 衣服 网站 动漫 绘图 软件...\n",
       "4          4  干槽症 自愈 太太 万岁 舒心 美国 干槽症 眼皮 怎么回事 麦当劳 旋风 勺子 吉林市 鹿..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FASTTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_file=\"./processed_data/train_data.csv\"\n",
    "train_data = pd.read_csv(saved_file)\n",
    "sentences =\"__label__\"+train_data[\"Gender\"].map(str)+\" , \"+train_data[\"Query\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing data to fasttext format...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"writing data to fasttext format...\")\n",
    "out = open('./processed_data/train_data.txt', 'w', encoding='utf-8')\n",
    "for sentence in sentences[:95000]:\n",
    "    out.write(sentence+\"\\n\")\n",
    "out.close()\n",
    "test=open('./processed_data/test_data.txt', 'w', encoding='utf-8')\n",
    "for sentence in sentences[95000:]:\n",
    "    test.write(sentence+\"\\n\")\n",
    "test.close()\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.7952\n",
      "R@1: 0.7952\n",
      "Number of examples: 5000\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\"\"\"\n",
    "  训练一个监督模型, 返回一个模型对象\n",
    "\n",
    "  @param input:           训练数据文件路径\n",
    "  @param lr:              学习率\n",
    "  @param dim:             向量维度\n",
    "  @param ws:              cbow模型时使用\n",
    "  @param epoch:           次数\n",
    "  @param minCount:        词频阈值, 小于该值在初始化时会过滤掉\n",
    "  @param minCountLabel:   类别阈值，类别小于该值初始化时会过滤掉\n",
    "  @param minn:            构造subword时最小char个数\n",
    "  @param maxn:            构造subword时最大char个数\n",
    "  @param neg:             负采样\n",
    "  @param wordNgrams:      n-gram个数\n",
    "  @param loss:            损失函数类型, softmax, ns: 负采样, hs: 分层softmax\n",
    "  @param bucket:          词扩充大小, [A, B]: A语料中包含的词向量, B不在语料中的词向量\n",
    "  @param thread:          线程个数, 每个线程处理输入数据的一段, 0号线程负责loss输出\n",
    "  @param lrUpdateRate:    学习率更新\n",
    "  @param t:               负采样阈值\n",
    "  @param label:           类别前缀\n",
    "  @param verbose:         ??\n",
    "  @param pretrainedVectors: 预训练的词向量文件路径, 如果word出现在文件夹中初始化不再随机\n",
    "  @return model object\n",
    "\"\"\"\n",
    "input_file=\"./processed_data/train_data.txt\"\n",
    "classifier = fasttext.train_supervised(input=input_file, dim=32, epoch=30,\n",
    "                                         lr=0.1, wordNgrams=3, loss='softmax')\n",
    "#classifier.save_model('classifier.model')\n",
    "\n",
    "result = classifier.test('./processed_data/test_data.txt')\n",
    "print('P@1:', result[1])\n",
    "print('R@1:', result[2])\n",
    "print('Number of examples:', result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "precision = result[1]\n",
    "recall = result[2]\n",
    "f1_score = round(2 * (precision * recall) / (precision + recall), 2)\n",
    "print(f1_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
